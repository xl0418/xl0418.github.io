<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Bash & R: Dealing with big data; read it! don't source it!]]></title>
    <url>%2F2019%2F03%2F20%2F2019-03-20-readdatadon%2F</url>
    <content type="text"><![CDATA[Recently, I was focusing on my 3rd PhD project with mathematical modeling. It was about the extension to the neutral theory. I am not gonna reveal it now but will bring back in the future. So I was away from the blog for a while and have to put machine learning series aside, although the derivation of the recurrent neural network is done. It is coming soon as well. Finally, the mathematical model has been done. I have some time to talk something that I’ve been doing except the modeling when waiting for the simulation results. In this post, I am gonna record a silly issue about loading data in R after extracting the a subset of a big data by Bash. The right matrix format to load in RIf you have tracked my posts, you may remember that I used a bash script to extract a matrix out of a big and complex structured m file (see here). But I mistakenly modified the matrix to fit the matrix format in R. What’s wrong with this format? It is a function to call instead of a data to load. Thus if the data in the structure() is very big, like 10000x10000, it is very time-consuming to run the function in R. But our aim is to read the matrix of this size or even larger. It is not supposed to be problematic for R. After a while of brainstorm, I kind of thought it might be due to the matrix format and the way I load the data in R. The command source() actually calls the function written in the sourced file. Thus, to create a matrix by using structure() it is easy to exceed the memory size. The solution is that we could use read.csv() to load the data into R, which is much faster and more efficient for large data sets. To achieve that, we need rewrite the raw data in a csv format. The following is how it looks like in the notepad Notice that the first line is left blank. It is supposed to put the headers for columns. Then we can directly read it in R by using 1x = read.csv(data,header = FALSE) Super fast and it’s done. Finally, to extract the matrix from the raw data, you can just follow what I did before (here)). And replace the 6-15th lines with 12345A=$(grep -c 'D'&#123;'length(D)+1'&#125;' = \[' HDs"$j$i".Rdata)B=$[$A-1]sed '/D'&#123;'length(D)+1'&#125;'/&#123;G;s/\nX\&#123;'$B'\&#125;//;tend;x;s/^/X/;x;P;d&#125;;p;d;:end;s/D'&#123;'length(D)+1'&#125;'/D/;:a;n;ba' HDs"$j$i".Rdata&gt;HDt"$j$i".Rdatased -n '/D = \[/,/\];/p' HDt"$j$i".Rdata&gt;HD"$j$i".csvsed -i -e 's/D = \[//' -e 's/\];//' -e 's/ /,/g' -e 's/,;//g' HD"$j$i".csv where I just replace the space by the comma and delete the first and last line of the raw matrix. The ; at the end of each line is also removed. Enjoy!]]></content>
      <categories>
        <category>Research</category>
        <category>Bash</category>
        <category>sed</category>
      </categories>
      <tags>
        <tag>bash</tag>
        <tag>R</tag>
        <tag>data analysis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine learning on biology S2: how does a neural network work mathematically?]]></title>
    <url>%2F2019%2F02%2F08%2F2019-02-08-Machinelearningseries2%2F</url>
    <content type="text"><![CDATA[There are tons of documents out there to explain how neural network works in different angles. So I guess people don’t mind me adding one more from my perspective. Hopefully, someone may get inspired from this post. In short, the neural network is a kind of system that transforms the input data into its corresponding output (or labels), strictly speaking, for a supervised learning. This system is consisting of three types of layers, i.e. the input layer, the hidden layer and the output layer. Normally, the hidden layer may have multiple layers according to one’s design. Among layers, the data from the upper layer are transformed to the data in the lower layer via a linear combination with an initialized weight matrix. After that, a nonlinear transformation that is generally called the activation function is applied to the data that would be converted to a form for the next round until reaching the output layer. To assure the neural network feedback the correct output, people need to train the neural network by adjusting the weight matrix. They are usually adjusted via minimizing the error between the output from the final layer and the known output from the data used for training. Without loss of generality, here I consider a simplest neural network which only possesses fully connected layers, meaning that every neuron in each layer connects all neurons of the upper and lower layers. The mathematical logic behind is analogous to other structures of neural network. Firstly, I used a series of graphs to illustrate how the data flows to the final layer and introduce the notations used in the derivation. Then, a general formulation is present subsequently. A 6-layer neural networkThe following four graphs illustrate how the data evolves along the neural network and the notations used in the derivation. 1 Forward flow of the neural networkConsider a neural network with \(k+1\) layers including the input layer and the output layer. The input data is consisting of \(n\) samples with \(L_{1}\) features The output label is given accordingly where the label on the top left denotes the index of the sample. Too abstract? Imagine that sample \(^{1}\boldsymbol{x}\) corresponds to model 1 while sample \(^{2}\boldsymbol{x}\) corresponds to model 2. Then the output can be either an array of two vectors indicating the probabilities of model 1 and model 2, for example, \({(1,0),(0,1)}\), or a vector of two elements \({0,1}\) where 0 indicates model 1 and 1 indicates model 2 or whatever you label them. The purpose is to use a huge amount of data sets to train the neural network, more precisely to compute the weight matrix among the adjacent pair of layers, to fit the output layer to the output vectors. Will see it later on. Now, let’s feed one sample (the first one \(^{1}\boldsymbol{x}\)) to the neural network to see how to compute the output layer. Later, we will see how to train the network with multiple samples. Assume the second layer has \(L_{2}\) neurons Note that the first layer is the input layer in which we feed one sample with \(L_{1}\) feature to the neural network at first. Then the weight matrix from the first layer to the second layer is defined as Thus, multiplying the weight matrix Eq.4 with the neurons of the upper layer Eq.3 yields More generally, a bias term (constant term) is incorporated as follows which can also be written in the form if we absorb the constant vector \(\boldsymbol{b}_{1}\) into the weight matrix After the transformation, an activation function is applied to \(\boldsymbol{z}^{(2)}\) elementwisely. For a model classification problem, the sigmoid function and the hyperbolic tangent function are widely used. Here we use the sigmoid function for instance Till now, the transformation from the first layer (the input layer) to the second layer (the first hidden layer) is done. This process can be generalized as . where \(\boldsymbol{a}’\) is the vector \(\boldsymbol{a}\) absorbing 1 at the end as what I did in Eq.8. Note that \(\boldsymbol{a}^{(1)}=^{1}\boldsymbol{x}\). Finally, the neural network will return \(\boldsymbol{a}^{(k+1)}\) with \(L_{k+1}\) elements from the output layer. Given the corresponding output label \(\boldsymbol{y}^{(1)}\), we can compute the error between the feedback \(\boldsymbol{a}^{(k+1)}\) and the output label \(\boldsymbol{y}^{(1)}\). This is normally called the loss of the result to the output. There are several candidate loss functions for model classification like the least square, the cross-entropy function. We take the least square function as the example So far, we have computed out the loss of the neural network with a bunch of randomly initialized weight matrix. No doubt, the loss would be huge. Our aim is to minimized the loss \(J\) by tuning the weight matrix. How? Remember your advanced calculus in the high school or the university? \(J\) can be envisaged as a function of every entry in the weight matrix that we want to adjust. Thus, the derivative of \(J\) with respect to each entries of the weight matrix would tell us how to tune the weight matrix to minimize the loss. This method is called gradient descend. And the loss can also propagate backwards to determine the gradient of the entries of the weight matrix at each layer. The full process to tune the weight matrix is also called Backward Propagation. 2 Backward propagationFrom the \(k+1\)th layer to the \(k\)th layerLet us start from the final layer (the \(k+1\)th layer) to the previous one (the \(k\)th layer). Note that the variable of our concern is the entry of the weight matrix from the \(k\)th layer to the \(k+1\)th layer, \(\theta_{L_{k+1}\times L_{k}}^{(k)}\). Here I only consider tuning \(\theta\) instead of \(\theta’\), meaning that the bias terms are not tuned. Updating the bias terms is similar and you can practice it afterward. The derivative of the loss function with respect to the matrix is defined as At the mean time, from the loss function Eq.10, we obtain the derivative according to the chain rule where and where \(\otimes\) is the outer product. Simplifying the gradient Eq.12 yields If we define The gradient Eq.17 can be further simplified as Note that we define the outer product of two column vectors is the element-wise produce of the corresponding elements Now, as \(\boldsymbol{z}^{(k+1)}\), \(\boldsymbol{a}^{(k+1)}\) and \(^{1}\boldsymbol{y}\) are known, we can update the weight matrix \(\theta^{(k)}\) by where \(\lambda\) is a constant called the learning rate given in advance. From the \(k\)th layer to the \(k-1\)th layerLet’s do the calculation one more time from the \(k\)th layer to the \(k-1\)th layer. At the end of this section, we will get a general formula to update all weight matrix via which we can develop the algorithm for a deep neural network. Now we consider one more previous weight matrix \(\theta^{(k-1)}\). The derivative of the loss function with respect to that matrix yields The first two terms on the right hand side are the same as Eq.12. The third term \(\frac{\partial\boldsymbol{z}^{(k+1)}}{\partial\boldsymbol{a}^{(k)}}\) produces the weight matrix from the \(k+1\)th layer to the \(k\)th layer The last two terms on the right hand side are similar to what we have done above. Finally, we get Comparing Eq.19 and Eq.23 tells us that we can update the error for each transition among layers. This is how the error propagates backwards along the neural network and where the name comes from. Note that this expression is a slightly different from the formula in Chapter 9.2 of the machine learning course by Andrew Ng of Standford. Do you see why is that? 3 Training multiple samplesWe have derived mathematically how to train one sample on a neural network. How about multiple samples? Easy. Because all the weight matrix of the neural network are shared for all samples, we can update the weight matrix by a fraction of error of each sample. Normally this fraction is \(\frac{1}{\text{sample size}}\) where in our example the sample size is \(n\) Then, the weight matrix is tuned to minimize the error of samples. 4 Program a neural networkTill now, we have derived a general formula Eq.23 to allow us to update all weight matrix. After updating, the loss function is applied again to examine if the error is sufficiently small. If not, update the weight matrix again till meeting our criterion. Understanding the math behind is a huge step towards the expert level but not the final one. Whether you can equip it via code is essential. Here I attached my code in Python from my perspective as a reference. The user can add any number of hidden layers and deploy any number of neurons there. It is a bit like a minimalistic version of tensorflow. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import numpy as npimport pandas as pdclass neuralnetwork: # initialize parameters def __init__(self,num_sample,num_hidden_layer_units,num_input_feature,num_output_feature,bias,learningrate): self.learningrate=learningrate # learning rate self.num_sample = num_sample # number of the samples self.num_hidden_layer_units = num_hidden_layer_units # a list indicating the number of hidden layers and how many neurons for each layer self.num_hidden_layer = len(num_hidden_layer_units) # the number of the hidden layers self.weight_layer = [] # initialize the weight matrix self.bias = bias # bias for the input layer and for the hidden layers assert len(self.bias) == self.num_hidden_layer+1, "The length of the biases should equal the length of the hidden layers plus 1!!!" self.units = [num_input_feature] + num_hidden_layer_units + [num_output_feature] # randomly initialize the weight matrix for num_layer in range(0,len(self.units)-1): temp_bias = np.zeros((1,self.units[num_layer+1])) temp_bias.fill(self.bias[num_layer]) self.weight_layer.append(np.concatenate((np.random.randn(self.units[num_layer+1], self.units[num_layer]),temp_bias.T),axis = 1)) # the activation function: sigmoid # could be replaced by whatever you want def sigmoid(self,x): y = 1/(1+np.exp(-x)) return y # train function requires the training data, accuracy and iteration limit def train(self, input, output,accuracy, iteration_limit): go_on = True i = 0 # iteration indicator error = [] # error list recoding errors for all iterations iteration = [] while go_on: iteration.append(i) error_acc = 0 # initialize error for every iteration stderror = [] # standard error sample_Z = [] # Z value of neurons for every sample sample_a = [] # sigmoid value of Z for every sample # loop all samples for sample_iter in range(self.num_sample): Zlayer = [] a = [] a.append(input[sample_iter]) # place the input as the first a value # forward computing Z and a values for all layers for forward_layer in range(len(self.units)-1): Zlayer.append(np.matmul(self.weight_layer[forward_layer], np.concatenate((a[forward_layer],[1])))) a.append(self.sigmoid(Zlayer[forward_layer])) # standard error by computing the distance between output layer and true output stderror.append(a[len(a)-1]-output[sample_iter]) # loss function defined as the sum of the least square # can be replaced by other functions like cross-entropy error_acc += (1/2*np.sum((stderror[sample_iter])**2)) sample_a.append(a) # store a values for updating sample_Z.append(Zlayer) # store Z values for updating error.append(error_acc) # store error for this iteration # backward propagate errors to update the weight matrix i += 1 if error[i-1] &lt;accuracy or i &gt;iteration_limit: go_on = False else: for sample_iter in range(self.num_sample): delta = stderror[sample_iter] # delta: standard error defined as the derivative of the loss function # initialize g'(z): the derivative of the activation function at the output layer deriv_sigmoid = sample_a[sample_iter][len(sample_a[sample_iter])-1] *\ (1 - sample_a[sample_iter][len(sample_a[sample_iter])-1]) # backward propagation for backward_layer in list(reversed(range(len(self.units)-1))): temp_weight = self.weight_layer[backward_layer] # store the temporary kth matrix # update the kth matrix self.weight_layer[backward_layer][:,:-1] += - self.learningrate/self.num_sample *\ np.outer(delta * deriv_sigmoid, sample_a[sample_iter][backward_layer]) # update delta and derivative of the activation function delta = np.dot(temp_weight[:,:-1].T,delta * deriv_sigmoid) deriv_sigmoid = sample_a[sample_iter][backward_layer] *\ (1 - sample_a[sample_iter][backward_layer]) self.learningspeed = &#123;'error': error, 'iteration': iteration&#125; self.lsdf = pd.DataFrame(self.learningspeed) return sample_a, self.weight_layer # predict def predict(self,input,weight): out = input+[1] for i in range(len(weight)): out = np.dot(weight[i],np.array(out)) out = self.sigmoid(out) out = np.concatenate((out,[1])) return out[:-1]# testinputx = np.array(([0.2, 0.5, 0.5,0.3], [0.1, 0.2, 0.15,0.1],[0.7,0.9,0.4,0.8]))outputy = np.array(([0.5, 0.4], [0.9, 0.1],[0.3,0.5]))# build the neural networknn=neuralnetwork(num_sample=inputx.shape[0],num_hidden_layer_units=[15,14,15,16],num_input_feature=inputx.shape[1], num_output_feature=outputy.shape[1], bias=[0.1,0.2,0.3,0.4,0.4],learningrate=0.2)# set the accuracy and the iteration limitacc = 1e-7iter = 20000# train the neural networkout_a,weight = nn.train(inputx,outputy,accuracy = acc,iteration_limit=iter)# plot the learning processnn.lsdf.plot(x='iteration',y='error')# predictinput = [0.19, 0.51, 0.49,0.29]out = nn.predict(input,weight) You can also clone it on my Github The endMy code is obviously not the most efficient one as a lot of loops are used. But in another sense it is easy to read for a starter. As you see in the derivation and in the code, there are a huge amount of independent computing that can be parallelized to speed up. So the future plan is to parallelize the code on GPU which may substantially improve the efficiency of the neural network. It would also be a good practice for you to step into the machine learning field. Reference An introduction to the math used in Machine Learning: The Matrix Calculus You Need For Deep Learning . A concrete derivation of backward propagation for a two-layer neural network in Chinese here.]]></content>
      <categories>
        <category>Research</category>
        <category>Machine learning</category>
        <category>Deep learning</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Machine learning</tag>
        <tag>neural networks</tag>
        <tag>Backward propagation</tag>
        <tag>gradient descent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine learning on biology S1: model classification via ML]]></title>
    <url>%2F2019%2F02%2F01%2F2019-02-01-Machinelearningseries1%2F</url>
    <content type="text"><![CDATA[On my 2nd Phd project, I have constructed a complex trait-population model to describe how species evolve and assemble in a community under natural selection. However, people may naturally ask if such complexity is really needed. What is the discrepancy between the model with and without population dynamics and variable trait variance? To answer this question, a model selection/classification should be performed on the data generated under those candidate models. As what we used in parameter inference, an Approximate Bayesian Computation-Sequential Monte Carlo method is able to handle this work. However, a huge computational demanding is the bottle neck. To avoid to waste time on fitting each empirical data set by ABC-SMC, a method that only uses the feature of data sets would be a better choice. This reminds me the existing and fast-developed took, i.e. machine learning. So, from this post on, I would like to share my experience of learning Machine Leaning, how to construct a neural network, how to derive backwards propagation algorithm for leaning parameters of a neural network and how to use tensorflow to simply use machine learning, or even deep learning (a multiple-layer neural network algorithm), to do model selection/classification on the topic I mentioned above. A fast illustrationPresenting application at first would be concrete for people understand what I am talking about. Here in this simple example, I generated 200K data sets for each of the four models, i.e. Brownian Motion model, Ornstein Uhlenbeck (OU) model, Trait-population model, anti-Ornstein Uhlenbeck model. As a preliminary test, I just adjusted the parameter values for \(\gamma\) and \(\alpha\) to stand for 4 models, i.e. when \(\gamma=0,\alpha=0\) it stands for a Brownian Motion model; when \(\gamma&gt;0,\alpha=0\) it stands for an OU model; when \(\gamma=0,\alpha&gt;0\) it stands for an anti-OU model; when \(\gamma&gt;0,\alpha&gt;0\) it stands for a trait-population evolution (TP) model. I didn’t remove population dynamics from the BM and OU model. Therefore, the data generated by those two processes would be more alike to TP model than by the standard BM and OU model. The logic behind is that if the learning neural network can distinguish TP from the other 3 models, it is able to pick TP out from model pile with standard BM and OU model. Note that the anti-OU model is similar to Drury et al. model in 2018. When the parameter is nonzero, I simply randomly chose values as I assume we don’t know any prior information from the empirical data. I used in total around 1000K data sets that are randomly generated under 4 models but labeled with correct model names to train a simply three-layer neural network. It is super fast to train such small network and can be done within few minutes. Note that fitting data via ABC-SMC may coat a few days with 30 iterations and 200K particles for each iteration. Then I generated 100 data sets to feed the trained neural network. The generating models are known in advance. The purpose of this test is to check if the trained network is able to recognize the generating models. A preliminary resultThe result is shown below: Each chart contains four bars indicating the probability of each model (B: BM; O: OU; T: TP; A: Anti-OU). Color red denotes that the prediction of the network is wrong. Otherwise, the highest bar correctly implies the generating model. The results reveal that BM and OU model are confusing to the trained neural network. This makes sense that because of the normalization of traits the output of these two models show no significant discrepancy, i.e. almost all traits are evenly distributed in the trait space. Only the range of the traits would provide some information, i.e. BM model has wider range for the traits than OU model. But the normalization neglects it. The other two models, TP and Anti-OU are nicely distinguishable from the model pile. This indicates that the trait-population model do have significant pattern to express itself. Thus our complexity plays a role in describing trait patterns. Future planHere in the example, I only exploited a 3-layer neural network but already got a nice result. The issues of confusing BM and OU model may be resolved if a deep neural network is applied. Anyway, the power of machine learning on biology is shown and there are more improvement space waiting for further study. I do believe that machine learning can be useful in biology. But so far as I know, few literature present this tech on biology field. In fact, data analysis and pattern recognition are also key component in biological research besides modeling. I hope machine learning could attract biologist’s attention and thrive here like what it develops in industry and computer science. The endAs planed at the beginning, the following posts would be on machine learning. Coming soon!]]></content>
      <categories>
        <category>Research</category>
        <category>Machine learning</category>
        <category>Deep learning</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>GPU programming</tag>
        <tag>Machine learning</tag>
        <tag>neural networks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyCUDA series 3: matrix multiplication using multiple blocks]]></title>
    <url>%2F2019%2F01%2F21%2F2019-01-21-PyCUDAseries3%2F</url>
    <content type="text"><![CDATA[A simple practice on matrix multiplication is shown in this post. The matrix product function can use multiple blocks to calculate multiplications of two matrix. A simple matrix multiplicationThe most important part is the kernel function, which is given below 1234567891011121314151617181920212223242526kernel_code_template = """__global__ void matrixmulti(float *a, float *b, float *c)&#123; // 2D Thread ID int tx = blockDim.x*blockIdx.x + threadIdx.x; // Compute column index int ty = blockDim.y*blockIdx.y + threadIdx.y; // Compute row index // Each thread loads one row of M and one column of N, // to produce one element of P. if((ty &lt;%(MATRIX_SIZE)s) &amp;&amp; (tx &lt; %(MATRIX_SIZE)s)) &#123; // Pvalue is used to store the element of the matrix // that is computed by the thread float Pvalue = 0; for(int k=0; k&lt;%(MATRIX_SIZE)s;++k) &#123; float Aelement = a[ty*%(MATRIX_SIZE)s +k]; float Belement = b[k*%(MATRIX_SIZE)s +tx]; Pvalue += Aelement * Belement; &#125; c[ty * %(MATRIX_SIZE)s + tx] = Pvalue; &#125;&#125;""" Note that the evaluation of C should be put in the conditional loop to guarentee that over-requested threads would not be invoked. An odd bugThe code works well when the matrix size is less than 320*320 and requesting block size to be 32*32. But when the matrix size exceeds 320, like 321, the matrix product produced by GPU is not equal to the result by CPU. The difference between them is very tiny, like the scale of 1e-5. So far, I don’t quite understand where this bug comes from. Probabily it is due to the limit of the number of blocks in one grid? Full codeIt contains the example code and the speed test. Clone it here]]></content>
      <categories>
        <category>Research</category>
        <category>GPU programming</category>
        <category>pyCUDA</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CUDA</tag>
        <tag>GPU programming</tag>
        <tag>Parallel computation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyCUDA series 2: a simple matrix algebra and speed test]]></title>
    <url>%2F2019%2F01%2F14%2F2019-01-14-PyCUDAseries2%2F</url>
    <content type="text"><![CDATA[In this post, you will find a simple matrix algebra done by gpu parallelization and a straightforward result of the speed contest between cpu and gpu. A simple matrix algebra to be parallelizedAs a first try, I intended to parallleize a simple matrix algebra in my Project 2 that can be computed as follows on Python: 1c = a_cpu[:,np.newaxis]-a_cpu This is a formula to compute the discrepancy of any pair of elements given by a vector. For example, input 1a = np.array([1,2,3]) the formula should return 123c = array([[0,-1,-2,], [1,0,-1], [2,1,0]]) A standard python code like the formula above by using numpy package, every element in c_cpu is computed in a serial order. In terms of the power of current cpu, for a lower dimensional matrix, you can hardly feel the elapsed time to compute out the equation. However, if you have a huge matrix of 10000X10000 size and want to loop it 100 times, it costs half a minute on an i7 4790k cpu, although you may ignore the little time consumed. But it is not rare to have a large matrix bigger than 1 million by 1 million and loop it billion times at least in an evolutionary problem. In this case, you are saving your life if the compulation time can be reduced. A shortcut to understand GPU parallel computationNow we have a good way to save our life instead of having a weird pill. CUDA is a parallel computing platform and application programming interface (API) model created by Nvidia. PyCUDA provides a python package to allow people to parallelize their computation on a Graphic Processing Unit (GPU) by Python. For sure, I didn’t say everything is parallelizable. Only the procedures that are consisting of independent calculation paths can be parallelized, which means you work on different paths at the same time instead of doing them one by one. Hence, the amount of time that can be saved relies on the percentage of work that is parallelizable in your work. In this sense, matrix algebra is a good representative. Other applications of parallelism involves rendering graphics to a screen, running a Monte Carlo Simulation, multiplying matrices for a machine learning algorithm, or powering a database. Google them yourself. Why does GPU possess such powerful ability? It owes to its design purpose. A graphic card is designed to process graphics and render them to a screen. What is a graphic? It is just like a matrix. So to process a matrix, the ability to compute multiple entries of the matrix is more important than the ability to deal with just one entry smartly. Hence, a gpu is designed to own a huge amount of threads that can process multiple calculations at one time although they are slow while a cpu only contains few (like an i7 4790k has 4 physical cores which means 4 physical threads, at most 8 threads if including hyperthreads tech) but are faster. A good analogy is that a gpu is like a cluster of students at primary school while a cpu is like a professor. When calculating a complex problem, the professor is definitely faster and smarter. But when computing lots of simple algebra, the cluster of primary students is faster. In summary, CPUs are designed for running a small number of potentially quite complex tasks. GPUs are designed for running a large number of quitesimple tasks. Parallelize the matrix algebraAfter having a rough idea of parallelism, let’s do it on practice. For a matrix algebra like the above example, what are the independent calculation paths? Apparently, each entry of the output matrix c is computed out independently given the input a. Thus, we could assign each calculation path to a thread on GPU. 1234567891011121314151617181920212223242526kernel_code_template = """__global__ void com_t(int matrixsize,float *a, float *c)&#123; // 2D Thread ID int tx = blockDim.x*blockIdx.x + threadIdx.x; // Compute column index int ty = blockDim.y*blockIdx.y + threadIdx.y; // Compute row index // Pvalue is used to store the element of the matrix // that is computed by the thread float Pvalue = 0; // Each thread loads one row of M and one column of N, // to produce one element of P. if((ty &lt;matrixsize) &amp;&amp; (tx &lt; matrixsize)) &#123; float Aelement = a[ty]; float Belement = a[tx]; Pvalue = Aelement - Belement; // Write the matrix to device memory; // each thread writes one element c[ty * matrixsize + tx] = Pvalue; &#125;&#125;""" The most important part of parallelism on GPU is the kernel function which is coded for a single calculation path. The only difference among different calculation paths is the locality information of the entries of matrix c in the memory. Normally, we can envisage a memory on GPU as a cluster of grids of blocks of threads. But in fact, it is not this physical structure on the borad of the card. It involves streaming processors (SMs) dealing with wraps. However, here we better use the metaphor. Each entry in matrix c corresponds to a specific combination of gridIdx.x,gridIdx.y,blockIdx.x,blockIdx.y,threadIdx.x,threadIdx.y. The value of the indexes also depend on how we allocate the size of grid, block. A regular way for a matrix algebra is to fit the struture to the matrix. For example, if we want to compute a 5X5 matrix, we can allocate the size of block as 5X5 which means we will use a matrix of 5X5 threads for compuatation. But a block contains at most 1024 threads for the current card (GTX 970). Thus for a square matrix we can allocate at most a size of 32X32 threads for one block. If we want to work on a larger matrix, we need more blocks or even more grids. This then causes one issue that some threads may not be used if the matrix size is not a multiplier of the block size. Therefore, we need to constrain our computation within the matrix by using if((ty &lt;matrixsize) &amp;&amp; (tx &lt; matrixsize)). And make sure the evaluation of matrix c is put in the loop. Otherwise, the over requested threads (if the requested threads don’t fit the matrix size) will be invoked and replace the inner results in c. Once we have correctly allocated the memory and located the entry by these indexes, we can formulate your calculation. After that, the code will be uploaded to GPU and tranferred to the code of GPU (compile). Once all entries have been calculated, the results will be stored in the memory on GPU. Then cpu will pull back the result. 1234567891011121314151617181920# compile the kernel codemod = compiler.SourceModule(kernel_code_template)# get the kernel function from the compiled modulematrixmul = mod.get_function("com_t")matrixsize = 3BLOCK_SIZE = 2# call the kernel on the cardmatrixmul(np.uint32(matrixsize), # inputs a_gpu, # output c_gpu, # 4 blocks of BLOCK_SIZE x BLOCK_SIZE threads grid = (2,2,1), block = (BLOCK_SIZE, BLOCK_SIZE, 1), ) Speed comparison between CPU and GPUAt last, to show the power of GPU even on such simple matrix algebra, I run calculation for different dimensions and loop each calculation 100 times to enlarge the time consumption. As the figure shows, the time consumption for 100 times calculations starts to significantly split up when the dimension of matrix is over 2000. The time consumption on CPU grows almost exponentially along the dimension while on gpu it only grows a little. With the increase of dimension, you save a huge amount of your time and your life. EndThis is a quite simplified introduction to a parallelism example. There is a bank of posts explaining parallelism better and more exhaustive than this one. However, my goal here is to use a simple example and a short length of words to have you get an idea of how it works instead of scaring you away from this field. Once you fall into the trap of “it looks as simple as the author said”, I believe you will learn more by yourself :-) Reference[CUDA Programming] by Shane Cook is a good start book for learning both the hardware and the language. This PyCUDA website provides some examples on Python. Full codeIt contains the example code and the speed test. Clone it here]]></content>
      <categories>
        <category>Research</category>
        <category>GPU programming</category>
        <category>pyCUDA</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CUDA</tag>
        <tag>GPU programming</tag>
        <tag>Parallel computation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sed again: run on Ubuntu to avoid weird behavior]]></title>
    <url>%2F2019%2F01%2F10%2F2019-01-10sed2%2F</url>
    <content type="text"><![CDATA[As my 2nd project is close to an end, it is right the time to go back to the phylogenetic Janzen-Connell model. Simulations and plotting functions have been done during the gap time squeezed from the 2nd project. The last thing is to analyze the data, in which I bumped into a weird behavior of sed. The data fileIn this project, I have generated in total 108 data file in .m (Matlab) format. Each file contain several distance matrix, abundance vectors, an event table and turnover ticks that I want to extract and analyze exclusively. Extract the matrixThe procedure is simple. I modified the previous experimental bash scripts a bit to fit the file names of data. Then execute them sequentially on Windows prompt. Run extractallDs.sh and extractallRs.sh to extract all D matrix and R matrix from the raw files into LRsij.Rdata,MRsij.Rdata,HRsij.Rdata,LDsij.Rdata,MDsij.Rdata,HDsij.Rdata. Run Dlast.sh to extract the last D and R matrix into LDij.Rdata,LRij.Rdata,MDij.Rdata,MRij.Rdata,HDij.Rdata,HRij.Rdata. Do the same thing to extract event table and turnover ticks by running loopextractEve_Turn.sh like But I obtained nothing in the files. Bug shootingSame simulation code generates the same data structure. But why couldn’t the same bash script extract information as before? At that moment, I kind of had a feeling that it must be that the script cannot recognize the newline sign. like the following, if the computer cannot match \r, which is the code for the newline under windows and DOS, the script extracts nothing. 123456789#!/bin/bashfor j in &#123;0..4&#125;;dofor i in &#123;0..4&#125;;do sed -n '/D'&#123;'length(D)+1'&#125;' = \[\r/,/\];/p' test"$j$i".m &gt; Ds"$j$i".Rdataecho $j$i' done'donedone But after I changed it to \n that is the right code for a linux file, it didn’t work neither. Even after changing the file code via unix2dos, none of the means worked. \(\boldsymbol{Finally}\), after several hours of googling, thinking, patting the computer, I tried out the solution. The scripts need to be executed under the linux system. I launched them on Ubuntu again, the newline sign was recognized. But it is still a mystery to me that why on a windows prompt none of \r and \n can be recognized. If you know it, pls reply this post. Thanks!]]></content>
      <categories>
        <category>Research</category>
        <category>Bash</category>
        <category>sed</category>
      </categories>
      <tags>
        <tag>project 3</tag>
        <tag>bash</tag>
        <tag>mega data</tag>
        <tag>extract information</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyCUDA series 1: Build GPU programming environment]]></title>
    <url>%2F2019%2F01%2F04%2F2019-01-04-PyCUDAseries1%2F</url>
    <content type="text"><![CDATA[As my research always involves a huge amount of computation, parallel technique is a super fancy way to save my time. But the resource of cluster at my university is limited. I recently received a warning that CIT has detected multiple-account usage under my IP. To avoid the risk of being fired, I have to figure out another way to parallelize my job instead of parallelizing accounts. Right on time, GPU programming came out as an ideal option. I hope the GPU resource of my university is not full loaded yet. Due to some incompatibilities of CUDA and Visual Studio 2017, I spent half a day to figure out the solutions and finally succeeded building up GPU programming environment on Windows 10 with Pycuda installed in Python. Here, I post the procedure of the build and some solutions to the incompatibilities. PrerequisiteFor now, I am working on Windows 10 with Python 3.7.0. The CUDA version that is compatibly built up for me is CUDA 10.0. I used Pycharm 2018.3 as the Python IDE. Probably I will try to build on OS 10 soon in the future. Simple procedure Install Python 3.7 and PyCharm 2018.3. Install Visual Studio 2017 as CUDA needs C++ compile. Open the Visual Studio installer under the folder Visual Studio 2017. Select: Modify under Visual Studio 2017 -&gt; Installation details. Install options: select only the Windows 10 SDK. Install CUDA 10.0 and follow the steps here to set up CUDA environment. Tips To make sure that CUDA is successfully installed, check nvcc -v at your terminal. The step to build samples in Nvidia’s guide is not necessary. I couldn’t build the samples due to some incompatibilities of vs c++ but still have it work on Python. Problem shooting CUDA install failed I only came across this issue on my desktop at office that has an old monitor. Then, I resolved it by customizing the installation with uncheck of Visual Studio integration. No idea why but it works. Also check answer here nvcc fatal : Cannot find compiler ‘cl.exe’ in PATH Check here. In principle, you should add cl.exe to the environment variables.]]></content>
      <categories>
        <category>Research</category>
        <category>GPU programming</category>
        <category>pyCUDA</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>CUDA</tag>
        <tag>GPU programming</tag>
        <tag>Parallel computation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ggradar2: Help document]]></title>
    <url>%2F2018%2F12%2F07%2F2018-12-07-ggradar2helpdocument%2F</url>
    <content type="text"><![CDATA[In this blog, the details of the arguments used in ggradar2 are provided. ggradar2: argumentsplot.data :The input data should be in the data.frame format with columns named. The values in the data are supposed to be numeric. If you want to apply scales like ‘high’, ‘middle’, ‘low’. Please evaluate them first and put them as gridline.label . Notice that ‘group’ column is suggested to included in your data. ggradar2 now can smartly detect if ‘group’ is correctly provided. If not, you will be asked if the first column is allowed to defined as the group column. 1WARNING: &apos;group&apos; column is not detected. The first column will be chosen as the group name. Yes/no? (y/n) If you want to plot multiple plots against some subgroups, please specify it in the column data$facet1. base.size: The size of radar chart. The default value is 20. webtype: &quot;mini&quot; set a web type with 3 grid lines while &quot;lux&quot; set a type with 5 grid lines. Default setting is &quot;mini&quot;. axis.labels: The label of each column in your data is plotted around the radar. axis.label.offset: The offset of axis labels. axis.label.size: The size of axis labels. axis.line.colour: The color of axis labels. grid.min, grid.max: Rescale your values in this range. centre.y: The radius of inner circle. label.centre.y: TRUE prints the central value. FALSE turns it off. grid.line.width: The width of grid lines. grid.line.trend: &quot;classic&quot; sets equal width of the grid lines. &quot;increase&quot; sets an outward-increasing width of the grid lines. &quot;decrease&quot; sets an outward-decreasing width of the grid lines. gridline.min.linetype, gridline.mid.linetype, gridline.max.linetype: Set the grid line type for the inner, middle and outer circles. The default setting is &quot;longdash&quot;. gridline.min.colour, gridline.mid.colour, gridline.max.colour: Set the colors for the inner, middle and outer circles. The default settings are &quot;grey&quot;, &quot;#007A87&quot;, &quot;grey&quot;. grid.label.size: Set the size of grid labels. gridline.label.offset: The offset of grid labels. gridline.label: The default setting is the percentage. Replace it with your labels. group.line.width: The width of group lines. group.point.size: The size of the point in each axis for group lines. group.colours: Set colors for the group lines. polygonfill: Turn on/off the polygon fill. polygonfill.transparency: The transparency of polygon fills. group.fill.colours: The colors of polygon fills. background.circle.colour: The background color for the radar. background.circle.transparency: The transparency of the background. radarshape: &quot;round&quot; gives you a round radar. &quot;sharp&quot; gives you a sharp radar. multiplots: Turn on/off multi-plotting function. If on, data$facet1 column should be included in your data. TRUE/FALSE fullscore: Set full scores to your values. stripbackground: Turn on/off the background for the panels of multiple plots. The followings are basic settings. 1234legend.title="",plot.legend=TRUE,plot.title="",legend.text.size=14,]]></content>
      <categories>
        <category>Research</category>
        <category>Data visualization</category>
        <category>R</category>
        <category>ggradar2</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>ggplot</tag>
        <tag>Data visualization</tag>
        <tag>ggradar2</tag>
        <tag>help document</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ggradar2: deploy a radar to your data]]></title>
    <url>%2F2018%2F12%2F05%2F2018-12-05-ggradar2%2F</url>
    <content type="text"><![CDATA[ggradar2 is now available. A large amount of features have been added to make your radar chart powerful. See ggradar2 on my Github Introductionggradar2 is a gg-function to draw a radar plot for data analysis. It is stem from ggradar but has been extended with more cool features. Install ggradar2Run the code 1devtools::install_github("xl0418/ggradar2",dependencies=TRUE) Use ggradar2Load data.12345678910library(ggradar2)data(mtcars)% Extract the group names. Otherwise, the first column will be chosen as the group names.group = row.names(mtcars)df = cbind(group,mtcars)% The radar chart is not a nice presentation if you want to compare too many groups. Thus here % we only focus on 4 groups.dftest = head(df,4)% To better distinguish two different styles, 6 groups are selected for illustration.dftest = dftest[,1:7] Default styleBy default 1ggradar2(dftest) returns No fill with round gridIf you don’t want to fill the polygon, run 1ggradar2(dftest,polygonfill = FALSE) Web typeA new web type ‘lux’ has been added by webtype. mini type 1ggradar2(dftest,webtype = 'mini') luxurious type 1ggradar2(dftest,webtype = 'lux') Gird line trendUse grid.line.trend = &#39;increase&#39; to plot an outward-increasing grid lines. 123ggradar2(dftest,style = 'sharp',webtype = 'lux', group.line.width = 0.5,grid.line.trend = 'increase',gridline.min.linetype = 'solid', gridline.max.linetype = 'solid',gridline.min.colour = 'black',gridline.max.colour='black') Full scoreUse fullscore = c(...) to set the full score to each variable. 12fullscore &lt;- c(100,10,300,150,10,10)a &lt;- ggradar2(dftest,fullscore = fullscore) Sharp gridA new style has been added. Call out the straight line style by running 1ggradar2(dftest,style = 'sharp') Sharp grid without fillGet rid of the fill 1ggradar2(dftest,style = 'sharp',polygonfill = FALSE) Removing the legend12ggradar2(dftest,style = 'sharp',polygonfill = FALSE,plot.legend = FALSE) Multiple plots by subgroups1234567# Extract 3 brands of cars out of the data framefacettest &lt;- df[c(1,2,4,5,8:14),]# Set the subgroup namesfacet1 &lt;- mapply(rep,c('Mazda','Hornet','Merc'),c(2,2,7))facet1 &lt;- Reduce(c,facet1)facettest &lt;- cbind(facettest,facet1)ggradar2(facettest,multiplots = TRUE) Notice that the column name for the subgroups should be ‘facet1’. Otherwise, ggradar2 could not recognize it.]]></content>
      <categories>
        <category>Research</category>
        <category>Data visualization</category>
        <category>R</category>
        <category>ggradar2</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>ggplot</tag>
        <tag>Data visualization</tag>
        <tag>ggradar2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Draw the evolution of SMC]]></title>
    <url>%2F2018%2F11%2F30%2F2018-11-30-SMCplots%2F</url>
    <content type="text"><![CDATA[Finally, I have done visualizing the evolution of SMC in R instead of in Python. Here, two illustrations are given. Generating DataThe data I used in the examples is generated under SMC applying on our trait-population coevolution model, a likelihood-free method for searching the true parameters when an analytic formulation of the model is not achievable. The data is consisting of 30 iterations samples. Each iteration contains 10K sampling. The algorithm starts by sampling from a uniform distribution in range (0,1). After each iteration, it computes the fitness of the samples and highly weights the samples with high fitness. Finally, it converges to the true value. Mountain plotMountain plot is recently highly evaluated theme for comparing the distribution of data across groups. The idea is stem from Henrik’s plot Forget to point out the true value is at 1.0, which is the peak of the distribution at 30th iteration. Heatmap plotAnother nice presentation is realized by the heat map. The data was manipulated a bit. The density of the samples was converted to the frequency in tiny cells. Then it can be applied by the heat map plot. Which one do you prefer?]]></content>
      <categories>
        <category>Research</category>
        <category>Data visualization</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>ggplot</tag>
        <tag>SMC</tag>
        <tag>Data visualization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Color your plots]]></title>
    <url>%2F2018%2F11%2F29%2F2018-11-29-color%2F</url>
    <content type="text"><![CDATA[Share a fancy website that shows “Curated color palette”. GallerySome examples by using different colors. Plots are generated by ggtree. And the data is simulated under our model. Coming soon! PS: which one do you prefer? Or all suck…]]></content>
      <categories>
        <category>Research</category>
        <category>Data visualization</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>color</tag>
        <tag>python</tag>
        <tag>plot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R update all packages]]></title>
    <url>%2F2018%2F11%2F26%2F2018-11-26-Rupdateallpackages%2F</url>
    <content type="text"><![CDATA[A convenient way to update all the packages. Update all the packagesVery simple, just one piece of code as follows: 1update.packages(ask = FALSE, dependencies = c('Suggests')) Run it in the console of your Rstudio and take a cup of coffee.]]></content>
      <categories>
        <category>Research</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>update</tag>
        <tag>packages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sed:a fast way to extract information from data]]></title>
    <url>%2F2018%2F10%2F29%2F2018-10-29-sed%2F</url>
    <content type="text"><![CDATA[In the third project, a bunch of mega data are generated for analysis. However, the simulated data is too big to load in memory. Thus, I need to extract some information without opening the file. After quite a few time searching for a solution, sed command in bash language helps me out. More details about the third project is coming soon. The data fileThe data file contains a few snapshot on different time points. Some matrix are written in the file when a snapshot time is hit. These matrix may be very large according to the parameter settings you chose. What I want to extract is the matrix \(\boldsymbol{D}\) and \(\boldsymbol{R}\) at the end. Extracting the matrixFirstly, I extract all the \(\boldsymbol{D}\)s, for example, from the data file. The following code does the thing for me. 123456789#!/bin/bashfor j in &#123;0..4&#125;;dofor i in &#123;0..4&#125;;do sed -n '/D'&#123;'length(D)+1'&#125;' = \[\r/,/\];/p' test"$j$i".m &gt; Ds"$j$i".Rdataecho $j$i' done'donedone As you see, there are in total 25 data files I need to deal with. For each data file, sed finds the line starting with “\(D\left\{length(D)+1\right\} = [\)” till “\(];\)” from the file testji.m and writes/prints (\(p\)) all the matched lines to the file Dsji.Rdata. Replacing the last D matrixThen, I want to extract the last \(\boldsymbol{D}\) matrix. How can I do that? Use the following code: 123456789101112131415161718#!/bin/bashfor j in &#123;0..4&#125;;dofor i in &#123;0..4&#125;;do A=$(grep -c 'D'&#123;'length(D)+1'&#125;' = \[' Ds"$j$i".Rdata)B=$[$A-1]sed '/D'&#123;'length(D)+1'&#125;'/&#123;G;s/\nX\&#123;'$B'\&#125;//;tend;x;s/^/X/;x;P;d&#125;;p;d;:end;s/D'&#123;'length(D)+1'&#125;'/D/;:a;n;ba' Ds"$j$i".Rdata&gt;Dt"$j$i".Rdatased -n '/D = \[\r/,/\];/p' Dt"$j$i".Rdata &gt; D"$j$i".RdataC=$(cat D"$j$i".Rdata |wc -l)C=$[$C-2]D=$[$C+1]sed -i -e 's/D = \[/D = structure(c(/' -e 's/\];/),.Dim=c('$(echo $C)','$(echo $C)'))/' -e 's/;/ /g' -e '2,$&#123;s/ /,/g&#125;' -e '2,$&#123;s/,,/ /g&#125;' -e '3,'$(echo $D)'&#123;s/^/,/g&#125;' D"$j$i".Rdataecho $j$i' done'donedone The command grep returns the number of the replicates of the line “\(D\left\{length(D)+1\right\} = [\)”. Then sed replaces the head of the last matrix with \(D\) and extracts this matrix out and writes into file Dij.Rdata. As I want to work in R with these results, I reformat the structure of the results to fit the matrix format in R which is something like: 1D = structure(c(1,0,0,1),.Dim=c(2,2)) At last, I can directly source the file in R and read the matrix. Details in sedThe first sed in the second script is the key part in this function. 1sed '/D'&#123;'length(D)+1'&#125;'/&#123;G;s/\nX\&#123;'$B'\&#125;//;tend;x;s/^/X/;x;P;d&#125;;p;d;:end;s/D'&#123;'length(D)+1'&#125;'/D/;:a;n;ba' Ds"$j$i".Rdata&gt;Dt"$j$i".Rdata I don’t fully understand what every letter in this command means. In this answer, the author explained the idea is to store a \(X\) at each match in the holdspace, and when all the \(X\)s are there, loop till the end of file. If you know more, please comment after the post. Thanks! The third sed reformats the matrix to fit in R. -e executes several commands in one line. 1sed -i -e 's/D = \[/D = structure(c(/' -e 's/\];/),.Dim=c('$(echo $C)','$(echo $C)'))/' -e 's/;/ /g' -e '2,$&#123;s/ /,/g&#125;' -e '2,$&#123;s/,,/ /g&#125;' -e '3,'$(echo $D)'&#123;s/^/,/g&#125;' D"$j$i".Rdata The first segment replaces “\(D = [ \)” with “\(D = structure(c( \)” while the second replaces the tail “];” with “(,.Dim=c(row,col)”. Then all the signs “;” are substituted by space and the single space is substituted by “,” from the second line to the end. Following the replacement of “,,” by space from the second line and add “,” at the beginning of the line from the third line on. Finally, a standard matrix form is rebuilt. BTW, a good tutorial can be found here. Have fun!]]></content>
      <categories>
        <category>Research</category>
        <category>Bash</category>
        <category>sed</category>
      </categories>
      <tags>
        <tag>project 3</tag>
        <tag>bash</tag>
        <tag>mega data</tag>
        <tag>extract information</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Partial least square regression]]></title>
    <url>%2F2018%2F10%2F24%2F2018-10-25-PLSR%2F</url>
    <content type="text"><![CDATA[I found the following interpretation to partial least square regression is much better than mine. So I cited it as below: “Partial least squares regression (PLS regression) is a statistical method that bears some relation to principal components regression; instead of finding hyperplanes of maximum variance between the response and independent variables, it finds a linear regression model by projecting the predicted variables and the observable variables to a new space. Because both the X and Y data are projected to new spaces, the PLS family of methods are known as bilinear factor models. Partial least squares Discriminant Analysis (PLS-DA) is a variant used when the Y is categorical.” —from Wikipedia PLS algorithmFor record purpose, I am deriving the PLS algorithm in this post. Consider a linear regression problem in a vector format as in Eq.[eq:1] given an observed data, which is denoted by a vector \(\boldsymbol{x}^{T}=(x_{1},x_{2},\cdots,x_{n})\) $$\begin{align}y &amp;=b_{1}x_{1}+\cdots+b_{n}x_{n}+e \\ &amp;=\boldsymbol{x}^{T}\boldsymbol{b}+e \tag{1}\end{align}$$ We are aiming to work out the unknown regression coefficients vector \(\boldsymbol{b}\) for future prediction of \(y\) once we have the observed data \(\boldsymbol{x}\). To keep the prediction as accurate as possible, we will want to make the residual error e as small as possible. This is simply the whole idea of the linear regression method. So one solution is to use training samples, that is given m observations \(\boldsymbol{y}^{T}=(y_{1},\cdots,y_{m}),X=[x_{ij}],i=1,\cdots,m,j=1,\cdots,n \)to solve \(\boldsymbol{b}\) out in terms of keeping the residual error sufficiently small $$\begin{pmatrix}y_{1}\\y_{2}\\\vdots\\y_{m}\end{pmatrix}=\begin{pmatrix}x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1n}\\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2n}\\\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\x_{m1} &amp; x_{m2} &amp; \cdots &amp; x_{mn}\end{pmatrix}\begin{pmatrix}b_{1}\\b_{2}\\\vdots\\b_{n}\end{pmatrix}+\begin{pmatrix}e_{1}\\e_{2}\\\vdots\\e_{m}\end{pmatrix}\tag{2}$$ For comparability among different data, all the observations are assumed to be centered and normalized in advance. Now the problem is translated to an optimization problem, that is to find a least square solution for the regression coefficients such that the sum of the square errors of the residuals is minimized. For simplicity, I would like to use the matrix form for Eq.[2] $$Y=X\boldsymbol{b}+\boldsymbol{e}. \tag{3}$$ We want to find out \(\boldsymbol{b}\) such that $$min\{\boldsymbol{e}^{T}\boldsymbol{e}\}.$$ The least square solution for \(\boldsymbol{b}\) is given by $$\boldsymbol{b}=(X^{T}X)^{-1}X^{T}Y. \tag{4}$$ The derivation is simply as follows: $$F_{\boldsymbol{b}}=\frac{1}{2}(X\boldsymbol{b}-Y)^{T}(X\boldsymbol{b}-Y) \tag{5}$$ So the derivative of F_{\boldsymbol{b}} yields $$\begin{align}\nabla_{\boldsymbol{b}}F_{\boldsymbol{b}}&amp;=\frac{1}{2}\nabla_{\boldsymbol{b}}(X\boldsymbol{b}-Y)^{T}(X\boldsymbol{b}-Y)\\ &amp;=\frac{1}{2}\nabla_{\boldsymbol{b}}(\boldsymbol{b}^{T}X^{T}-Y^{T})(X\boldsymbol{b}-Y)\\ &amp;=\frac{1}{2}\nabla_{\boldsymbol{b}}(\boldsymbol{b}^{T}X^{T}X\boldsymbol{b}-\boldsymbol{b}^{T}X^{T}Y-Y^{T}X\boldsymbol{b}+Y^{T}Y)\\ &amp;=\frac{1}{2}\nabla_{\boldsymbol{b}}tr(\boldsymbol{b}^{T}X^{T}X\boldsymbol{b}-\boldsymbol{b}^{T}X^{T}Y-Y^{T}X\boldsymbol{b}+Y^{T}Y)\\ &amp;=\frac{1}{2}\nabla_{\boldsymbol{b}}\left(tr(\boldsymbol{b}^{T}X^{T}X\boldsymbol{b})-2tr(Y^{T}X\boldsymbol{b})+tr(Y^{T}Y)\right)\\ &amp;=X^{T}X\boldsymbol{b}-X^{T}Y.\end{align}$$ By setting the derivative to be 0, solution Eq.[4] is obtained.However, this least square solution may have problem when the training sample is not enough, that is m&lt;n. In that case, the matrix \(X^{T}X\) doesn’t have full rank which means it is nonsingular. To solve this problem, we can project each measurement \(\boldsymbol{x_{i}}=(x_{i1},\cdots,x_{in})\) into a lower-dimensional subspace spanned by data \(T=XW\). We can think of this as forming a smaller set of features, each being the linear combination of the original set of features. These new features are also called “latent” variables. Therefore, the linear regression can be written as a linear regression system on the new latent variables $$\begin{align}Y &amp;=TQ^{T}+F \tag{6} \\X &amp;=TP^{T}+E \tag{7}\end{align}$$ where \(P,Q\) are the coefficient matrices and E,F are matrices of errors. As in partial least squares regression (PLSR), the weight matrix \(W\) reflects the covariance structure between the predictor and response variables. Hence, maximizing the covariance of the latent variables and the response variables \(Cov(T,Y)\) gives us the weight matrix \(W\). Once obtaining \(W\) and then constructing \(T\), \(Q^{T}\) is solved by the least squares solution Eq.[6]: $$Q^{T}=(T^{T}T)^{-1}T^{T}Y.$$ Plug Eq.[eq:latent] into the regression equation Eq.[6], we obtain the solution of the matrix \(\boldsymbol{b}\) of the coefficient in the model Eq.[3] $$\boldsymbol{b}=W(T^{T}T)^{-1}T^{T}Y.$$ So this is the whole idea of PLS. A commonly used algorithm to compute PLSR is the nonlinear iterative partial least square (NIPALS) method. The steps are summarized as follows: NIPALS Normalize \(m\) training samples by $$\begin{align}x_{ij} &amp;=\left(x_{ij}-\bar{x} _{\cdot\ j}\right)/ \sigma _{x_{\cdot\ j}} \\y_{i} &amp;=\left(y_{i}-\bar{y}\right)/ \sigma _{y}\ \text{for }i=1,\cdots,m,j=1,\cdots,n\end{align}$$ Compute the scores Compute the dominant eigenvector of \(X_{0}^{T}Y_{0}Y_{0}^{T}X_{0}\) and assign it to \(w_{1}\) (the step of maximizing the covariance). Normalize \(w_{1}\). The scores \(t_{1}\) of \(X_{0}\) yields $$t_{1}=X_{0}w_{1}.$$ Do the same to \(Y_{0}\) and obtain a normalized vector \(c_{1}\). The scores \(v_{1}\) of \(Y_{0}\) yields $$v_{1}=Y_{0}c_{1}.$$ Compute the loadings Based on the regression equations $$\begin{align}X &amp;=t_{1}p_{1}^{T}+E \\Y &amp;=t_{1}q_{1}^{T}+F,\end{align}$$ the least square method gives us $$\begin{align}p_{1} &amp;=\frac{X^{T}t_{1}}{t_{1}t_{1}^{T}} \\q_{1} &amp;=\frac{Y^{T}t_{1}}{t_{1}t_{1}^{T}}.\end{align}$$ Check if \(F\) is sufficiently small. Otherwise, set \(E\) as \(X_{1}\), \(F\) as \(Y_{1}\). Repeat step 2-3. Finally, we obtain $$\begin{align}X &amp;=t_{1}p_{1}^{T}+t_{2}p_{2}^{T}+\cdots+t_{n}p_{n}^{T}+E \\Y &amp;=t_{1}q_{1}^{T}+t_{2}q_{2}^{T}+\cdots+t_{n}q_{n}^{T}+F\end{align}$$ which in a matrix format is as follows: $$\begin{align}X &amp;=TP^{T}+E \\Y &amp;=TQ^{T}+F \\ &amp;=XWQ^{T}+F \\ &amp;:=XB+F.\end{align}$$ So, when we have a new data \(x_{new}\), to define the PLS components in our ABC-MCMC algorithm, we only need to compute $$t_{1}=x_{new}^{T}p_{1},t_{2}=x_{new}^{T}p_{2},\cdots,t_{n}=x_{new}^{T}p_{n}$$]]></content>
      <categories>
        <category>Research</category>
        <category>Numerical method</category>
      </categories>
      <tags>
        <tag>math</tag>
        <tag>regression</tag>
        <tag>least square method</tag>
        <tag>partial least square</tag>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deriving the Fokker-Planck equation from a stochastic differential equation]]></title>
    <url>%2F2018%2F10%2F24%2F2018-10-24-derivingFPequ%2F</url>
    <content type="text"><![CDATA[Writing a periodic progress report is a good way to record the process that you gain knowledge. Reviewing my progress reports in the last 3 years, it recovers my memory about the knowledge and technologies that I almost forgot as I rarely use them. From this post on, I would like to give them a review and share on the blog. Hope it can help people who are interest in and one can help me if I am wrong at somewhere. DerivationHere I briefly present the derivation for the Fokker-Planck equation from a stochastic differential equation. Given the stochastic process $$dx=a(x,t)dt+b(x,t)dW_{t}$$ where \(W_{t}\) is a Wiener process. By Ito lemma, for any twice-differentiable scalar function \(f(x)\) we have $$df(x)=\left(a(x,t)f’(x)+\frac{1}{2}b^{2}(x,t)f’’(x)\right)dt+b(x,t)f’(x)dW_{t}$$ The expectation of \(f(x,t)\) yields $$E(f(x))=\int f(x)p(x,t)dx$$ and take the derivative $$\frac{dE(f(x))}{dt}=\frac{d\int f(x)p(x,t)dx}{dt}=\int f(x)\frac{\partial p(x,t)}{\partial t}dx \tag{1}$$ Also, we could plug Eq.[1] in the expectation of \(f(x)\) and take the derivative yields $$\frac{dE(f(x))}{dt}=\frac{E(df(x))}{dt}=E\left(a(x,t)f’(x)+\frac{1}{2}b^{2}(x,t)f’’(x)\right) \tag{2}$$ From that Eq.[1] and Eq.[2] are identical, we have $$\begin{align}\int f(x)\frac{\partial p(x,t)}{\partial t}dx &amp;=\int\left(a(x,t)f’(x)+\frac{1}{2}b^{2}(x,t)f’’(x)\right)p(x,t)dx \\ &amp; =\int a(x,t)f’(x)p(x,t)dx+\frac{1}{2}\int b^{2}(x,t)f’’(x)p(x,t)dx \\ &amp; =-\int f(x)\frac{\partial a(x,t)p(x,t)}{\partial x}dx+\frac{1}{2}\int f(x)\frac{\partial^{2}b^{2}(x,t)p(x,t)}{\partial x^{2}}dx \\ &amp; =\int f(x)\left(-\frac{\partial a(x,t)p(x,t)}{\partial x}+\frac{1}{2}\frac{\partial^{2}b^{2}(x,t)p(x,t)}{\partial x^{2}}\right)dx\end{align}$$ As \(f(x)\) is arbitrary, we obtain the Fokker-Planck equation in one dimension $$\frac{\partial p(x,t)}{\partial t}=-\frac{\partial a(x,t)p(x,t)}{\partial x}+\frac{1}{2}\frac{\partial^{2}b^{2}(x,t)p(x,t)}{\partial x^{2}}$$]]></content>
      <categories>
        <category>Research</category>
        <category>Stochastic differential equations</category>
      </categories>
      <tags>
        <tag>mathematical modeling</tag>
        <tag>the Fokker-Planck equation</tag>
        <tag>stochastic differential equation</tag>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pruneL function]]></title>
    <url>%2F2018%2F10%2F24%2F2018-10-24-pruneLfunction%2F</url>
    <content type="text"><![CDATA[I guess this function is specially useful to our group in which we play with L table. But might be less useful than phylo2L function :-) Following last post, this function pruneL prunes an L table by removing the extinct lineages. pruneL function can be found here if you want to improve the function. There is a huge room for improvement. This version is only the first draft of the function. And I guess I should remove the argument dropextinct. It doesn’t make any sense. What do you think?]]></content>
      <categories>
        <category>Research</category>
        <category>R</category>
        <category>phylogeny function</category>
      </categories>
      <tags>
        <tag>phylogeny</tag>
        <tag>phylo class</tag>
        <tag>L table</tag>
        <tag>DDD package</tag>
        <tag>pruneL</tag>
        <tag>phylo2L</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[phylo2L function]]></title>
    <url>%2F2018%2F10%2F24%2F2018-10-24-phylo2Lfunction%2F</url>
    <content type="text"><![CDATA[I guess this function is specially useful to our group in which we play with L table. L table is an alternative way to a phylo class for phylogenetic information storage. The function L2phylo has been implemented in the DDD package that converts an L table to a phylo class. This function phylo2L does the conversion the other way around. Thus, if you want to apply your model to an empirical data. This may be useful to you. phylo2L function can be found here if you want to improve the function. I have verified it by examining if L=phylo2L(L2phylo(L)) Notice that phylo2L doesn’t have the argument dropextinct as what L2phylo has. Because to my perspective L table should be consistent with the given phylo class. But if you have a full tree on hand and want to prune it, you can do it like this prune_phylo = L2phylo(phylo2L(full tree), dropextinct = TRUE) prune_L = phylo2L(prune_phylo) Or you can use pruneL function that I have developed to prune an L table. More details on pruneL function can be found in this post.]]></content>
      <categories>
        <category>R</category>
        <category>phylogeny function</category>
      </categories>
      <tags>
        <tag>phylogeny</tag>
        <tag>phylo class</tag>
        <tag>L table</tag>
        <tag>DDD package</tag>
        <tag>pruneL</tag>
        <tag>phylo2L</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Blogging tech]]></title>
    <url>%2F2018%2F10%2F23%2F2018-10-23-Blogging%20tech%2F</url>
    <content type="text"><![CDATA[I am using hexo for blogging. The blog website is built on my personal Github Page. The theme of the blog is next which is a powerful tool to customize the blog. Here I would like to share/archive some useful tech for future use. Optimizing the themeTwo posts are recommended here on zhihu and CSDN. They almost contain all the custom adjustments for the theme. Of course, the official website next is a good choice as well.Advance tech to make your blog prettier is on this website. Huge amount of tips and tricks are shown. MaterialsTo look for some materials like pictures, icons, you can find a lot form easyicon and fontawesome for free.]]></content>
      <categories>
        <category>Blogging</category>
        <category>Blogging tech</category>
      </categories>
      <tags>
        <tag>Tech</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PhD Project 1-Detecting local diversity-dependence in diversification]]></title>
    <url>%2F2018%2F10%2F22%2F2018-10-22-IntrotoPro1%2F</url>
    <content type="text"><![CDATA[Welcome to Liang&apos;s blog! This is my first PhD project since 2015 joining Etienne&apos;s lab. You will find a brief introduction to this project. The code for the model can be found on my GitHub. This my first formal research project starting from December of 2015 to February 2018 when the paper gets published. It seems to take quite a long time. Because I spent some time to switch from mathematics to evolutionary science and writing paper costs time as well. Anyway, to commemorate the first paper. AbstractWhether there are ecological limits to species diversification is a hotly debated topic. Molecular phylogenies show slowdowns in lineage accumulation, suggesting that speciation rates decline with increasing diversity. A maximum likelihood method to detect diversity-dependent diversification from phylogenetic branching times exists, but it assumes that diversity-dependence is a global phenomenon and therefore ignores that the underlying species interactions are mostly local, and not all species in the phylogeny co-occur locally. Here, we explore whether this maximum likelihood method based on the non-spatial diversity-dependence model can detect local diversity-dependence, by applying it to phylogenies, simulated with a spatial stochastic model of local-diversity-dependent speciation, extinction and dispersal between two local communities. We find that type I errors (falsely detecting diversity-dependence) are low, and the power to detect diversity-dependence is high when dispersal rates are not too low. Interestingly, when dispersal is high the power to detect diversity-dependence is even higher than in the non-spatial model. Moreover, estimates of intrinsic speciation rate, extinction rate and ecological limit strongly depend on dispersal rate. We conclude that the non-spatial diversity-dependent approach can be used to detect diversity-dependence in clades of species that live in not too disconnected areas, but parameter estimates must be interpreted cautiously. ModelWe have developed a spatial diversity-dependent diversification model to explore if the global version of the diversity-dependence approach could detect the diversity-dependent signal on the spatial scenario. Generating treesThe idea is simple. For simplicity, we build a two-location model and let species evolve (speciate: give birth to a new species/ extinction: one species goes extinct) in the regime. A pack of generated trees under different speciation rates and extinction rates and dispersal rates is like this (Scenario 2, see details in our paper): Applying the bootstrapping analysisWe exploit the bootstrapping analysis to examine the power of the global approah to detect the signal of diversity-dependence on the spatial structered trees. The following tables show the power of the global tool for signal detection under different parameter combinations and scenarios. Parameter inferenceAs due to the complexity of the model, an analytical likelihood function is not possible to achieve. Therefore, we test if the global likelihood approach can recover the parameters on the spatial model or show some patterns. ConclusionFrom the results above, the conclusion is clear. Please see our paper:-) ReferenceXu, L., &amp; Etienne, R. S. (2018). Detecting local diversity-dependence in diversification. Evolution, 72(6), 1294-1305. DOI: 10.1111/evo.13482 Etienne, R. S., Pigot, A. L., &amp; Phillimore, A. B. (2016). How reliably can we infer diversity-dependent diversification from phylogenies? Methods in ecology and evolution, 7(9), 1092-1099. DOI: 10.1111/2041-210X.12565 Etienne, R. S., Haegeman, B., Stadler, T., Aze, T., Pearson, P. N., Purvis, A., &amp; Phillimore, A. B. (2012). Diversity-dependence brings molecular phylogenies closer to agreement with the fossil record. Proceedings of the Royal Society of London. Series B, Biological Sciences, 279(1732), 1300-1309. DOI: 10.1098/rspb.2011.1439]]></content>
      <categories>
        <category>Research</category>
        <category>Phd projects</category>
      </categories>
      <tags>
        <tag>evolution</tag>
        <tag>mathematical modeling</tag>
        <tag>diversity-dependence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F10%2F22%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Liang&apos;s blog! This site is my first blog for sharing my work experience plus a little bit life. CategoriesResearchThis category mainly contains my PhD projects so far. More details can be found on my Research Gate. BB lifeSome interesting stuff about life. BB, in Chinese, means talk about, chat. WorkNot on work yet, although 3 years ago I was a lecturer in China. BloggingInteresting technologies about blogging. At last, enjoy the blog. Hope you can find something useful. Or at least have fun :-)]]></content>
      <categories>
        <category>BB life</category>
      </categories>
      <tags>
        <tag>info</tag>
      </tags>
  </entry>
</search>
