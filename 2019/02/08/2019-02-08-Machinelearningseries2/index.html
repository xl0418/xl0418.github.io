<!DOCTYPE html>













<html class="theme-next muse" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.4.2" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=6.4.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon16.ico?v=6.4.2">


  <link rel="mask-icon" href="/images/logo.svg?v=6.4.2" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.4.2',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="There are tons of documents out there to explain how neural network works in different angles. So I guess people don’t mind me adding one more from my perspective. Hopefully, someone may get inspired">
<meta name="keywords" content="Python,Machine learning,neural networks,Backward propagation,gradient descent">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine learning on biology S2: how does a neural network work mathematically?">
<meta property="og:url" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/index.html">
<meta property="og:site_name" content="Liang Xu">
<meta property="og:description" content="There are tons of documents out there to explain how neural network works in different angles. So I guess people don’t mind me adding one more from my perspective. Hopefully, someone may get inspired">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/step1.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/step2.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/step3.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/step4.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/step5.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/step8.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/step7.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/step6.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/1.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/2.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/3.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/4.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/5.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/6.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/78.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/9.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/9-1.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/10.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/11.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/12.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/13-15.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/16.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/17.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/18.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/19.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/19-1.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/20.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/21.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/22.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/23.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/24.png">
<meta property="og:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/25.png">
<meta property="og:updated_time" content="2020-03-21T21:48:47.159Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine learning on biology S2: how does a neural network work mathematically?">
<meta name="twitter:description" content="There are tons of documents out there to explain how neural network works in different angles. So I guess people don’t mind me adding one more from my perspective. Hopefully, someone may get inspired">
<meta name="twitter:image" content="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/step1.png">






  <link rel="canonical" href="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Machine learning on biology S2: how does a neural network work mathematically? | Liang Xu</title>
  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127999589-"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127999589-');
</script>






  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
	<a href="https://github.com/xl0418"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>
    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Liang Xu</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">This is Liang's blog for life and work archive.</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>Search</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://xl0418.github.io/2019/02/08/2019-02-08-Machinelearningseries2/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Xu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Liang Xu">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Machine learning on biology S2: how does a neural network work mathematically?
              
            
          </h1>
          

        <div class="post-meta">
		    
			  <i class="fa fa-thumb-tack"></i>
			  <font color="7D26CD">TOP</font>
			  <span class="post-meta-divider">|</span>
			
            <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-08 13:06:06" itemprop="dateCreated datePublished" datetime="2019-02-08T13:06:06+01:00">2019-02-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-03-21 22:48:47" itemprop="dateModified" datetime="2020-03-21T22:48:47+01:00">2020-03-21</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Research/" itemprop="url" rel="index"><span itemprop="name">Research</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Research/Machine-learning/" itemprop="url" rel="index"><span itemprop="name">Machine learning</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Research/Machine-learning/Deep-learning/" itemprop="url" rel="index"><span itemprop="name">Deep learning</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/02/08/2019-02-08-Machinelearningseries2/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">Comments: </span> <span class="post-comments-count valine-comment-count" data-xid="/2019/02/08/2019-02-08-Machinelearningseries2/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article: </span>
                
                <span title="Symbols count in article">15k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">11 mins.</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>There are tons of documents out there to explain how neural network works in different angles. So I guess people don’t mind me adding one more from my perspective. Hopefully, someone may get inspired from this post.</p>
<a id="more"></a>
<p>In short, the neural network is a kind of system that transforms the input data into its corresponding output (or labels), strictly speaking, for a supervised learning. This system is consisting of three types of layers, i.e. the input layer, the hidden layer and the output layer. Normally, the hidden layer may have multiple layers according to one’s design. Among layers, the data from the upper layer are transformed to the data in the lower layer via a linear combination with an initialized weight matrix. After that, a nonlinear transformation that is generally called the activation function is applied to the data that would be converted to a form for the next round until reaching the output layer. To assure the neural network feedback the correct output, people need to train the neural network by adjusting the weight matrix. They are usually adjusted via minimizing the error between the output from the final layer and the known output from the data used for training. </p>
<p>Without loss of generality, here I consider a simplest neural network which only possesses fully connected layers, meaning that every neuron in each layer connects all neurons of the upper and lower layers. The mathematical logic behind is analogous to other structures of neural network. Firstly, I used a series of graphs to illustrate how the data flows to the final layer and introduce the notations used in the derivation. Then, a general formulation is present subsequently.</p>
<h1 id="A-6-layer-neural-network"><a href="#A-6-layer-neural-network" class="headerlink" title="A 6-layer neural network"></a>A 6-layer neural network</h1><p>The following four graphs illustrate how the data evolves along the neural network and the notations used in the derivation.</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/step1.png" alt="fig">    </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/step2.png" alt="fig">    </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/step3.png" alt="fig">    </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/step4.png" alt="fig">   </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/step5.png" alt="fig"> </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/step8.png" alt="fig">         </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/step7.png" alt="fig">     </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/step6.png" alt="fig">     </p>
<h1 id="1-Forward-flow-of-the-neural-network"><a href="#1-Forward-flow-of-the-neural-network" class="headerlink" title="1 Forward flow of the neural network"></a>1 Forward flow of the neural network</h1><p>Consider a neural network with \(k+1\) layers including the input layer and the output layer. The input data is consisting of \(n\) samples with \(L_{1}\) features</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/1.png" alt="fig">   </p>
<p>The output label is given accordingly</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/2.png" alt="fig">   </p>
<p>where the label on the top left denotes the index of the sample. Too abstract? Imagine that sample \(^{1}\boldsymbol{x}\) corresponds to model 1 while sample \(^{2}\boldsymbol{x}\) corresponds to model 2. Then the output can be either an array of two vectors indicating the probabilities of model 1 and model 2, for example, \({(1,0),(0,1)}\), or a vector of two elements \({0,1}\) where 0 indicates model 1 and 1 indicates model 2 or whatever you label them. The purpose is to use a huge amount of data sets to train the neural network, more precisely to compute the weight matrix among the adjacent pair of layers, to fit the output layer to the output vectors. Will see it later on.</p>
<p>Now, let’s feed one sample (the first one \(^{1}\boldsymbol{x}\)) to the neural network to see how to compute the output layer. Later, we will see how to train the network with multiple samples. Assume the second layer has \(L_{2}\) neurons</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/3.png" alt="fig">   </p>
<p>Note that the first layer is the input layer in which we feed one sample with \(L_{1}\) feature to the neural network at first. Then the weight matrix from the first layer to the second layer is defined as </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/4.png" alt="fig">   </p>
<p>Thus, multiplying the weight matrix Eq.4 with the neurons of the upper layer Eq.3 yields</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/5.png" alt="fig">   </p>
<p>More generally, a bias term (constant term) is incorporated as follows</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/6.png" alt="fig"> </p>
<p>which can also be written in the form if we absorb the constant vector \(\boldsymbol{b}_{1}\) into the weight matrix  </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/78.png" alt="fig"> </p>
<p>After the transformation, an activation function is applied to \(\boldsymbol{z}^{(2)}\) elementwisely. For a model classification problem, the sigmoid function and the hyperbolic tangent function are widely used. Here we use the sigmoid function for instance</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/9.png" alt="fig"> </p>
<p>Till now, the transformation from the first layer (the input layer) to the second layer (the first hidden layer) is done. This process can be generalized as .</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/9-1.png" alt="fig"> </p>
<p>where \(\boldsymbol{a}’\) is the vector \(\boldsymbol{a}\) absorbing 1 at the end as what I did in Eq.8. Note that \(\boldsymbol{a}^{(1)}=^{1}\boldsymbol{x}\).</p>
<p>Finally, the neural network will return \(\boldsymbol{a}^{(k+1)}\) with \(L_{k+1}\) elements from the output layer. Given the corresponding output label \(\boldsymbol{y}^{(1)}\), we can compute the error between the feedback \(\boldsymbol{a}^{(k+1)}\) and the output label \(\boldsymbol{y}^{(1)}\). This is normally called the loss of the result to the output. There are several candidate loss functions for model classification like the least square, the cross-entropy function. We take the least square function as the example</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/10.png" alt="fig"> </p>
<p>So far, we have computed out the loss of the neural network with a bunch of randomly initialized weight matrix. No doubt, the loss would be huge. Our aim is to minimized the loss \(J\) by tuning the weight matrix. How? Remember your advanced calculus in the high school or the university? \(J\) can be envisaged as a function of every entry in the weight matrix that we want to adjust. Thus, the derivative of \(J\) with respect to each entries of the weight matrix would tell us how to tune the weight matrix to minimize the loss. This method is called gradient descend. And the loss can also propagate backwards to determine the gradient of the entries of the weight matrix at each layer. The full process to tune the weight matrix is also called Backward Propagation. </p>
<h1 id="2-Backward-propagation"><a href="#2-Backward-propagation" class="headerlink" title="2 Backward propagation"></a>2 Backward propagation</h1><h2 id="From-the-k-1-th-layer-to-the-k-th-layer"><a href="#From-the-k-1-th-layer-to-the-k-th-layer" class="headerlink" title="From the \(k+1\)th layer to the \(k\)th layer"></a>From the \(k+1\)th layer to the \(k\)th layer</h2><p>Let us start from the final layer (the \(k+1\)th layer) to the previous one (the \(k\)th layer). Note that the variable of our concern is the entry of the weight matrix from the \(k\)th layer to the \(k+1\)th layer, \(\theta_{L_{k+1}\times L_{k}}^{(k)}\). Here I only consider tuning \(\theta\) instead of \(\theta’\), meaning that the bias terms are not tuned. Updating the bias terms is similar and you can practice it afterward. The derivative of the loss function with respect to the matrix is defined as </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/11.png" alt="fig"> </p>
<p>At the mean time, from the loss function Eq.10, we obtain the derivative according to the chain rule</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/12.png" alt="fig"> </p>
<p>where</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/13-15.png" alt="fig"> </p>
<p>and</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/16.png" alt="fig"> </p>
<p>where \(\otimes\) is the outer product. Simplifying the gradient Eq.12 yields</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/17.png" alt="fig"> </p>
<p>If we define</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/18.png" alt="fig"> </p>
<p>The gradient Eq.17 can be further simplified as</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/19.png" alt="fig"> </p>
<p>Note that we define the outer product of two column vectors is the element-wise produce of the corresponding elements</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/19-1.png" alt="fig"> </p>
<p>Now, as \(\boldsymbol{z}^{(k+1)}\), \(\boldsymbol{a}^{(k+1)}\) and \(^{1}\boldsymbol{y}\) are known, we can update the weight matrix \(\theta^{(k)}\) by</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/20.png" alt="fig"> </p>
<p>where \(\lambda\) is a constant called the learning rate given in advance. </p>
<h2 id="From-the-k-th-layer-to-the-k-1-th-layer"><a href="#From-the-k-th-layer-to-the-k-1-th-layer" class="headerlink" title="From the \(k\)th layer to the \(k-1\)th layer"></a>From the \(k\)th layer to the \(k-1\)th layer</h2><p>Let’s do the calculation one more time from the \(k\)th layer to the \(k-1\)th layer. At the end of this section, we will get a general formula to update all weight matrix via which we can develop the algorithm for a deep neural network. </p>
<p>Now we consider one more previous weight matrix \(\theta^{(k-1)}\). The derivative of the loss function with respect to that matrix yields </p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/21.png" alt="fig"> </p>
<p>The first two terms on the right hand side are the same as Eq.12. The third term \(\frac{\partial\boldsymbol{z}^{(k+1)}}{\partial\boldsymbol{a}^{(k)}}\) produces the weight matrix from the \(k+1\)th layer to the \(k\)th layer</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/22.png" alt="fig"> </p>
<p>The last two terms on the right hand side are similar to what we have done above. Finally, we get</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/23.png" alt="fig"> </p>
<p>Comparing Eq.19 and Eq.23 tells us that we can update the error</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/24.png" alt="fig"> </p>
<p>for each transition among layers. This is how the error propagates backwards along the neural network and where the name comes from. Note that this expression is a slightly different from the formula in Chapter 9.2 of the <a href="https://www.coursera.org/course/ml" target="_blank" rel="noopener">machine learning course</a> by Andrew Ng of Standford. Do you see why is that? </p>
<h1 id="3-Training-multiple-samples"><a href="#3-Training-multiple-samples" class="headerlink" title="3 Training multiple samples"></a>3 Training multiple samples</h1><p>We have derived mathematically how to train one sample on a neural network. How about multiple samples? Easy. Because all the weight matrix of the neural network are shared for all samples, we can update the weight matrix by a fraction of error of each sample. Normally this fraction is \(\frac{1}{\text{sample size}}\) where in our example the sample size is \(n\)</p>
<p><img src="/2019/02/08/2019-02-08-Machinelearningseries2/25.png" alt="fig"> </p>
<p>Then, the weight matrix is tuned to minimize the error of samples. </p>
<h1 id="4-Program-a-neural-network"><a href="#4-Program-a-neural-network" class="headerlink" title="4 Program a neural network"></a>4 Program a neural network</h1><p>Till now, we have derived a general formula Eq.23 to allow us to update all weight matrix. After updating, the loss function is applied again to examine if the error is sufficiently small. If not, update the weight matrix again till meeting our criterion. Understanding the math behind is a huge step towards the expert level but not the final one. Whether you can equip it via code is essential. Here I attached my code in Python from my perspective as a reference. The user can add any number of hidden layers and deploy any number of neurons there. It is a bit like a minimalistic version of tensorflow. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">neuralnetwork</span>:</span></span><br><span class="line">    <span class="comment"># initialize parameters</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,num_sample,num_hidden_layer_units,num_input_feature,num_output_feature,bias,learningrate)</span>:</span></span><br><span class="line">        self.learningrate=learningrate <span class="comment"># learning rate</span></span><br><span class="line">        self.num_sample = num_sample  <span class="comment"># number of the samples</span></span><br><span class="line">        self.num_hidden_layer_units = num_hidden_layer_units <span class="comment"># a list indicating the number of hidden layers and how many neurons for each layer</span></span><br><span class="line">        self.num_hidden_layer = len(num_hidden_layer_units) <span class="comment"># the number of the hidden layers</span></span><br><span class="line">        self.weight_layer = []  <span class="comment"># initialize the weight matrix</span></span><br><span class="line">        self.bias = bias   <span class="comment"># bias for the input layer and for the hidden layers</span></span><br><span class="line">        <span class="keyword">assert</span> len(self.bias) == self.num_hidden_layer+<span class="number">1</span>, <span class="string">"The length of the biases should equal the length of the hidden layers plus 1!!!"</span></span><br><span class="line">        self.units = [num_input_feature] + num_hidden_layer_units + [num_output_feature]</span><br><span class="line">        <span class="comment"># randomly initialize the weight matrix</span></span><br><span class="line">        <span class="keyword">for</span> num_layer <span class="keyword">in</span> range(<span class="number">0</span>,len(self.units)<span class="number">-1</span>):</span><br><span class="line">            temp_bias = np.zeros((<span class="number">1</span>,self.units[num_layer+<span class="number">1</span>]))</span><br><span class="line">            temp_bias.fill(self.bias[num_layer])</span><br><span class="line">            self.weight_layer.append(np.concatenate((np.random.randn(self.units[num_layer+<span class="number">1</span>],</span><br><span class="line">                                                self.units[num_layer]),temp_bias.T),axis = <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the activation function: sigmoid</span></span><br><span class="line">    <span class="comment"># could be replaced by whatever you want</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        y = <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># train function requires the training data, accuracy and iteration limit</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, input, output,accuracy, iteration_limit)</span>:</span></span><br><span class="line">        go_on = <span class="keyword">True</span></span><br><span class="line">        i = <span class="number">0</span> <span class="comment"># iteration indicator</span></span><br><span class="line">        error = []  <span class="comment"># error list recoding errors for all iterations</span></span><br><span class="line">        iteration = []</span><br><span class="line">        <span class="keyword">while</span> go_on:</span><br><span class="line">            iteration.append(i)</span><br><span class="line">            error_acc = <span class="number">0</span>   <span class="comment"># initialize error for every iteration</span></span><br><span class="line">            stderror = []   <span class="comment"># standard error</span></span><br><span class="line">            sample_Z = []   <span class="comment"># Z value of neurons for every sample</span></span><br><span class="line">            sample_a = []   <span class="comment"># sigmoid value of Z for every sample</span></span><br><span class="line">            <span class="comment"># loop all samples</span></span><br><span class="line">            <span class="keyword">for</span> sample_iter <span class="keyword">in</span> range(self.num_sample):</span><br><span class="line">                Zlayer = []</span><br><span class="line">                a = []</span><br><span class="line">                a.append(input[sample_iter])    <span class="comment"># place the input as the first a value</span></span><br><span class="line">                <span class="comment"># forward computing Z and a values for all layers</span></span><br><span class="line">                <span class="keyword">for</span> forward_layer <span class="keyword">in</span> range(len(self.units)<span class="number">-1</span>):</span><br><span class="line">                    Zlayer.append(np.matmul(self.weight_layer[forward_layer], np.concatenate((a[forward_layer],[<span class="number">1</span>]))))</span><br><span class="line">                    a.append(self.sigmoid(Zlayer[forward_layer]))</span><br><span class="line">                <span class="comment"># standard error by computing the distance between output layer and true output</span></span><br><span class="line">                stderror.append(a[len(a)<span class="number">-1</span>]-output[sample_iter])</span><br><span class="line">                <span class="comment"># loss function defined as the sum of the least square</span></span><br><span class="line">                <span class="comment"># can be replaced by other functions like cross-entropy</span></span><br><span class="line">                error_acc += (<span class="number">1</span>/<span class="number">2</span>*np.sum((stderror[sample_iter])**<span class="number">2</span>))</span><br><span class="line">                sample_a.append(a)  <span class="comment"># store a values for updating</span></span><br><span class="line">                sample_Z.append(Zlayer) <span class="comment"># store Z values for updating</span></span><br><span class="line">            error.append(error_acc) <span class="comment"># store error for this iteration</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># backward propagate errors to update the weight matrix</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> error[i<span class="number">-1</span>] &lt;accuracy <span class="keyword">or</span> i &gt;iteration_limit:</span><br><span class="line">                go_on = <span class="keyword">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> sample_iter <span class="keyword">in</span> range(self.num_sample):</span><br><span class="line">                    delta = stderror[sample_iter]  <span class="comment"># delta: standard error defined as the derivative of the loss function</span></span><br><span class="line">                    <span class="comment"># initialize g'(z): the derivative of the activation function at the output layer</span></span><br><span class="line">                    deriv_sigmoid =  sample_a[sample_iter][len(sample_a[sample_iter])<span class="number">-1</span>] *\</span><br><span class="line">                                 (<span class="number">1</span> - sample_a[sample_iter][len(sample_a[sample_iter])<span class="number">-1</span>])</span><br><span class="line">                    <span class="comment"># backward propagation</span></span><br><span class="line">                    <span class="keyword">for</span> backward_layer <span class="keyword">in</span> list(reversed(range(len(self.units)<span class="number">-1</span>))):</span><br><span class="line">                        temp_weight = self.weight_layer[backward_layer] <span class="comment"># store the temporary kth matrix</span></span><br><span class="line">                        <span class="comment"># update the kth matrix</span></span><br><span class="line">                        self.weight_layer[backward_layer][:,:<span class="number">-1</span>] += - self.learningrate/self.num_sample *\</span><br><span class="line">                            np.outer(delta * deriv_sigmoid, sample_a[sample_iter][backward_layer])</span><br><span class="line">                        <span class="comment"># update delta and derivative of the activation function</span></span><br><span class="line">                        delta = np.dot(temp_weight[:,:<span class="number">-1</span>].T,delta * deriv_sigmoid)</span><br><span class="line">                        deriv_sigmoid = sample_a[sample_iter][backward_layer] *\</span><br><span class="line">                                 (<span class="number">1</span> - sample_a[sample_iter][backward_layer])</span><br><span class="line">        self.learningspeed = &#123;<span class="string">'error'</span>: error, <span class="string">'iteration'</span>: iteration&#125;</span><br><span class="line">        self.lsdf = pd.DataFrame(self.learningspeed)</span><br><span class="line">        <span class="keyword">return</span> sample_a, self.weight_layer</span><br><span class="line"></span><br><span class="line">    <span class="comment"># predict</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self,input,weight)</span>:</span></span><br><span class="line">        out = input+[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(weight)):</span><br><span class="line">            out = np.dot(weight[i],np.array(out))</span><br><span class="line">            out = self.sigmoid(out)</span><br><span class="line">            out = np.concatenate((out,[<span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">return</span> out[:<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line">inputx = np.array(([<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.5</span>,<span class="number">0.3</span>], [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.15</span>,<span class="number">0.1</span>],[<span class="number">0.7</span>,<span class="number">0.9</span>,<span class="number">0.4</span>,<span class="number">0.8</span>]))</span><br><span class="line">outputy = np.array(([<span class="number">0.5</span>, <span class="number">0.4</span>], [<span class="number">0.9</span>, <span class="number">0.1</span>],[<span class="number">0.3</span>,<span class="number">0.5</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># build the neural network</span></span><br><span class="line">nn=neuralnetwork(num_sample=inputx.shape[<span class="number">0</span>],num_hidden_layer_units=[<span class="number">15</span>,<span class="number">14</span>,<span class="number">15</span>,<span class="number">16</span>],num_input_feature=inputx.shape[<span class="number">1</span>],</span><br><span class="line">             num_output_feature=outputy.shape[<span class="number">1</span>], bias=[<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.4</span>,<span class="number">0.4</span>],learningrate=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set the accuracy and the iteration limit</span></span><br><span class="line">acc = <span class="number">1e-7</span></span><br><span class="line">iter = <span class="number">20000</span></span><br><span class="line"><span class="comment"># train the neural network</span></span><br><span class="line">out_a,weight = nn.train(inputx,outputy,accuracy = acc,iteration_limit=iter)</span><br><span class="line"><span class="comment"># plot the learning process</span></span><br><span class="line">nn.lsdf.plot(x=<span class="string">'iteration'</span>,y=<span class="string">'error'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict</span></span><br><span class="line">input = [<span class="number">0.19</span>, <span class="number">0.51</span>, <span class="number">0.49</span>,<span class="number">0.29</span>]</span><br><span class="line">out = nn.predict(input,weight)</span><br></pre></td></tr></table></figure>
<p>You can also clone it <a href="https://github.com/xl0418/Tensorflow/blob/master/NeuralNetwork.py" target="_blank" rel="noopener">on my Github</a> </p>
<h1 id="The-end"><a href="#The-end" class="headerlink" title="The end"></a>The end</h1><p>My code is obviously not the most efficient one as a lot of loops are used. But in another sense it is easy to read for a starter. As you see in the derivation and in the code, there are a huge amount of independent computing that can be parallelized to speed up. So the future plan is to parallelize the code on GPU which may substantially improve the efficiency of the neural network. It would also be a good practice for you to step into the machine learning field. </p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><p>An introduction to the math used in Machine Learning:  <a href="https://explained.ai/matrix-calculus/index.html" target="_blank" rel="noopener">The Matrix Calculus You Need For Deep Learning
</a>.</p>
</li>
<li><p>A concrete derivation of backward propagation for a two-layer neural network in Chinese <a href="http://www.cnblogs.com/charlotte77/p/5629865.html#!comments" target="_blank" rel="noopener">here</a>.</p>
</li>
</ul>

      
    </div>

    

    
    
    
	<div>
	  
		<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------The End-------------</div>
    
</div>

	  
	</div>
    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
          
            <a href="/tags/Machine-learning/" rel="tag"><i class="fa fa-tag"></i> Machine learning</a>
          
            <a href="/tags/neural-networks/" rel="tag"><i class="fa fa-tag"></i> neural networks</a>
          
            <a href="/tags/Backward-propagation/" rel="tag"><i class="fa fa-tag"></i> Backward propagation</a>
          
            <a href="/tags/gradient-descent/" rel="tag"><i class="fa fa-tag"></i> gradient descent</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/01/2019-02-01-Machinelearningseries1/" rel="next" title="Machine learning on biology S1: model classification via ML">
                <i class="fa fa-chevron-left"></i> Machine learning on biology S1: model classification via ML
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/20/2019-03-20-readdatadon/" rel="prev" title="Bash & R: Dealing with big data; read it! don't source it!">
                Bash & R: Dealing with big data; read it! don't source it! <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Liang Xu</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">25</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">26</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">52</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/xl0418" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:xl0418@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>
	  
      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#A-6-layer-neural-network"><span class="nav-number">1.</span> <span class="nav-text">A 6-layer neural network</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Forward-flow-of-the-neural-network"><span class="nav-number">2.</span> <span class="nav-text">1 Forward flow of the neural network</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Backward-propagation"><span class="nav-number">3.</span> <span class="nav-text">2 Backward propagation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#From-the-k-1-th-layer-to-the-k-th-layer"><span class="nav-number">3.1.</span> <span class="nav-text">From the \(k+1\)th layer to the \(k\)th layer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#From-the-k-th-layer-to-the-k-1-th-layer"><span class="nav-number">3.2.</span> <span class="nav-text">From the \(k\)th layer to the \(k-1\)th layer</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Training-multiple-samples"><span class="nav-number">4.</span> <span class="nav-text">3 Training multiple samples</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Program-a-neural-network"><span class="nav-number">5.</span> <span class="nav-text">4 Program a neural network</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-end"><span class="nav-number">6.</span> <span class="nav-text">The end</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">7.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
	  
	    <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
		<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
		<div class="widget-wrap">
			<h3 class="widget-title">Tag Cloud</h3>
			<div id="myCanvasContainer" class="widget tagcloud">
				<canvas width="250" height="250" id="resCanvas" style="width=100%">
					<ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ABC/">ABC</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Animation/">Animation</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Backward-propagation/">Backward propagation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CUDA/">CUDA</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DDD-package/">DDD package</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-visualization/">Data visualization</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPU-programming/">GPU programming</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GUI/">GUI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/L-table/">L table</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-learning/">Machine learning</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Parallel-computation/">Parallel computation</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/R/">R</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SMC/">SMC</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tech/">Tech</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bash/">bash</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/color/">color</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/coronavirus/">coronavirus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-analysis/">data analysis</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diversity-dependence/">diversity-dependence</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ecology/">ecology</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/evolution/">evolution</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/extract-information/">extract information</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ggplot/">ggplot</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ggradar2/">ggradar2</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/government-measure/">government measure</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gradient-descent/">gradient descent</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/help-document/">help document</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/info/">info</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/least-square-method/">least square method</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/math/">math</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mathematical-modeling/">mathematical modeling</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mega-data/">mega data</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/models/">models</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/neural-networks/">neural networks</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/packages/">packages</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandemic/">pandemic</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/partial-least-square/">partial least square</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/phylo-class/">phylo class</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/phylo2L/">phylo2L</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/phylogeny/">phylogeny</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/plot/">plot</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/project-3/">project 3</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pruneL/">pruneL</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/regression/">regression</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/simulation/">simulation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stochastic-differential-equation/">stochastic differential equation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/the-Fokker-Planck-equation/">the Fokker-Planck equation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/update/">update</a><span class="tag-list-count">1</span></li></ul>
				</canvas>
			</div>
		</div>
	  
    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liang Xu</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="Symbols count total">83k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="Reading time total">1:01</span>
  
</div>











        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.4.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.4.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.4.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.2"></script>



  



  








  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'GYCokyefkCnIfDEuskXxw3v5-gzGzoHsz',
        appKey: '5FXx5s8boovD0n2GeKrgxUp7',
        placeholder: 'Click me!',
        avatar:'mm',
        meta:guest,
        pageSize:'10' || 10,
        visitor: false
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

  
  <script type="text/javascript" src="/lib/zclip/clipboard.min.js"></script>
<script type="text/javascript" src="/js/src/custom.js"></script>
</body>
</html>
